"""
Operators for Nano Banana Renderer
"""

import bpy
import bmesh
import os
import json
import tempfile
import time
import base64
from bpy.types import Operator
from bpy.props import StringProperty, BoolProperty
from mathutils import Matrix
import bpy_extras
from .properties import load_api_key, get_nano_banana_output_dir

# å°è¯•å¯¼å…¥requestsï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨å ä½ç¬¦
try:
    import requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False
    print("Warning: requests library not available. Some features may not work.")

class NANOBANANA_OT_api_key_dialog(Operator):
    """API Key Input Dialog"""
    bl_idname = "nano_banana.api_key_dialog"
    bl_label = "Enter Gemini API Key"
    bl_description = "Enter your Google Gemini API key for image generation"
    bl_options = {'REGISTER', 'UNDO'}
    
    api_key: StringProperty(
        name="API Key",
        description="Your Google Gemini API key from Google AI Studio",
        default="",
        options={'SKIP_SAVE'}
    )
    
    def execute(self, context):
        if not self.api_key.strip():
            self.report({'ERROR'}, "Please enter a valid API key")
            return {'CANCELLED'}
        
        # Save API key to scene properties
        context.scene.nano_banana.api_key = self.api_key
        
        # Test the API connection
        bpy.ops.nano_banana.setup_api()
        
        self.report({'INFO'}, "API key saved successfully!")
        return {'FINISHED'}
    
    def invoke(self, context, event):
        # Pre-fill with existing key if available
        if context.scene.nano_banana.api_key:
            self.api_key = context.scene.nano_banana.api_key
        
        return context.window_manager.invoke_props_dialog(self, width=400)
    
    def draw(self, context):
        layout = self.layout
        layout.label(text="Google Gemini API Configuration", icon='KEYFRAME_HLT')
        layout.separator()
        
        box = layout.box()
        box.label(text="Get your API key from Google AI Studio:")
        box.label(text="https://makersuite.google.com/app/apikey")
        
        layout.separator()
        layout.prop(self, "api_key", text="API Key")
        layout.separator()
        
        layout.label(text="This will be used for Gemini 2.5 Flash Image generation", icon='INFO')

class NANOBANANA_OT_setup_api(Operator):
    """Setup Gemini API connection"""
    bl_idname = "nano_banana.setup_api"
    bl_label = "Setup API"
    bl_description = "Test and setup Gemini API connection for image generation"
    
    def execute(self, context):
        props = context.scene.nano_banana
        
        if not props.api_key:
            # Show API key dialog if not set
            bpy.ops.nano_banana.api_key_dialog('INVOKE_DEFAULT')
            return {'CANCELLED'}
        
        # ç®€åŒ–çš„APIæµ‹è¯•ï¼Œä¸ä¾èµ–ç½‘ç»œè¯·æ±‚
        print(f"Testing API with key: {props.api_key[:10]}...")
        self.report({'INFO'}, f"API Key configured: {props.api_key[:10]}...")
        
        # æ¨¡æ‹ŸAPIæµ‹è¯•æˆåŠŸ
        print("API connection test completed (offline mode)")
        self.report({'INFO'}, "API setup complete!")
        return {'FINISHED'}

class NANOBANANA_OT_capture_viewport(bpy.types.Operator):
    """Capture current viewport for testing"""
    bl_idname = "nano_banana.capture_viewport"
    bl_label = "Test Viewport Capture"
    bl_description = "Test viewport capture functionality"
    bl_options = {'REGISTER', 'UNDO'}

    def execute(self, context):
        print("=== å¼€å§‹è§†å£æ•è·æµ‹è¯• ===")
        self.report({'INFO'}, "Starting viewport capture test...")
        
        try:
            # ç®€åŒ–çš„è§†å£æ•è·æµ‹è¯•
            print("æ­¥éª¤1: è®¾ç½®æ¸²æŸ“å‚æ•°...")
            
            # ä¿å­˜åŸå§‹è®¾ç½®
            original_engine = context.scene.render.engine
            original_x = context.scene.render.resolution_x
            original_y = context.scene.render.resolution_y
            
            # è®¾ç½®æµ‹è¯•å‚æ•°
            context.scene.render.engine = 'BLENDER_EEVEE_NEXT'
            context.scene.render.resolution_x = 512
            context.scene.render.resolution_y = 512
            
            print("æ­¥éª¤2: æ‰§è¡Œæ¸²æŸ“...")
            bpy.ops.render.render(write_still=False)
            
            print("æ­¥éª¤3: è·å–æ¸²æŸ“ç»“æœ...")
            if 'Render Result' in bpy.data.images:
                render_result = bpy.data.images['Render Result']
                print(f"âœ… è·å–åˆ°æ¸²æŸ“ç»“æœ: {render_result.name}, å°ºå¯¸: {render_result.size}")
                
                # åˆ›å»ºå‰¯æœ¬
                test_image = bpy.data.images.new("Viewport_Test", 512, 512)
                test_image.pixels = list(render_result.pixels)
                
                # åœ¨å›¾åƒç¼–è¾‘å™¨ä¸­æ˜¾ç¤º
                for area in context.screen.areas:
                    if area.type == 'IMAGE_EDITOR':
                        for space in area.spaces:
                            if space.type == 'IMAGE_EDITOR':
                                space.image = test_image
                                break
                        break
                
                print("âœ… è§†å£æ•è·æµ‹è¯•æˆåŠŸå®Œæˆï¼")
                self.report({'INFO'}, "Viewport capture test completed successfully!")
            else:
                print("âŒ æœªæ‰¾åˆ°æ¸²æŸ“ç»“æœ")
                self.report({'ERROR'}, "No render result found")
            
            # æ¢å¤åŸå§‹è®¾ç½®
            context.scene.render.engine = original_engine
            context.scene.render.resolution_x = original_x
            context.scene.render.resolution_y = original_y
            
            return {'FINISHED'}
            
        except Exception as e:
            print(f"âŒ è§†å£æ•è·æµ‹è¯•å¤±è´¥: {e}")
            self.report({'ERROR'}, f"Viewport capture test failed: {str(e)}")
            return {'CANCELLED'}


class NANOBANANA_OT_render_viewport(bpy.types.Operator):
    """Render current viewport using Gemini AI - FIXED VERSION"""
    bl_idname = "nano_banana.render_viewport_fixed"
    bl_label = "Render Viewport (Fixed)"
    bl_description = "Generate AI render of current viewport using camera capture"
    
    def execute(self, context):
        props = context.scene.nano_banana
        
        print("=== å¼€å§‹Nano Banana AIæ¸²æŸ“ ===")
        self.report({'INFO'}, "Starting Nano Banana AI render...")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ä¿å­˜
        if not bpy.data.is_saved:
            print("âš ï¸ è­¦å‘Šï¼šæ–‡ä»¶å°šæœªä¿å­˜")
            self.report({'WARNING'}, "Current file is not saved. Please save your .blend file first for better project organization.")
            # ä¸å¼ºåˆ¶é€€å‡ºï¼Œåªæ˜¯æé†’ç”¨æˆ·
        else:
            print(f"âœ… å½“å‰æ–‡ä»¶å·²ä¿å­˜: {bpy.data.filepath}")
            self.report({'INFO'}, f"Working with saved file: {os.path.basename(bpy.data.filepath)}")
        
        # å¼ºåˆ¶è¾“å‡ºåˆ°Info Log
        for area in context.screen.areas:
            if area.type == 'INFO':
                area.tag_redraw()
        
        if not props.api_key:
            print("é”™è¯¯ï¼šæœªè®¾ç½®APIå¯†é’¥")
            self.report({'ERROR'}, "Please setup API key first")
            return {'CANCELLED'}
        
        print(f"APIå¯†é’¥å·²è®¾ç½®: {props.api_key[:10]}...")
        self.report({'INFO'}, f"API key found: {props.api_key[:10]}...")
        
        # æ£€æŸ¥requestsåº“æ˜¯å¦å¯ç”¨
        if not REQUESTS_AVAILABLE:
            print("é”™è¯¯ï¼šrequestsåº“ä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡ŒAPIè°ƒç”¨")
            self.report({'ERROR'}, "Requests library not available. Please install requests in Blender Python.")
            return {'CANCELLED'}
        
        # ä½¿ç”¨æ­£ç¡®çš„Blender APIæ•è·æ‘„åƒæœºè§†å£
        try:
            print("æ­¥éª¤1: æ•è·æ‘„åƒæœºè§†å£...")
            self.report({'INFO'}, "Step 1: Capturing camera viewport...")
            
            # æ£€æŸ¥æ‘„åƒæœº
            if not context.scene.camera:
                print("âŒ é”™è¯¯ï¼šæ²¡æœ‰æ´»åŠ¨æ‘„åƒæœº")
                self.report({'ERROR'}, "No active camera found")
                return {'CANCELLED'}
            
            print(f"ä½¿ç”¨æ‘„åƒæœº: {context.scene.camera.name}")
            
            # ç›´æ¥ä½¿ç”¨æ ‡å‡†æ¸²æŸ“API
            viewport_image = self.capture_viewport(context)
            
            if not viewport_image:
                print("âŒ è§†å£æ•è·å¤±è´¥")
                self.report({'ERROR'}, "Failed to capture viewport")
                return {'CANCELLED'}
            
            print(f"âœ… è§†å£æ•è·æˆåŠŸ: {viewport_image.name}")
            render_result = viewport_image
            if not render_result:
                print("é”™è¯¯ï¼šæ¸²æŸ“å¤±è´¥")
                self.report({'ERROR'}, "Failed to perform render")
                return {'CANCELLED'}
            
            print(f"æ¸²æŸ“å®Œæˆ: {render_result.name}, å°ºå¯¸: {render_result.size}")
            self.report({'INFO'}, f"Render completed: {render_result.name}")
            
            # Generate AI render
            print("æ­¥éª¤2: è°ƒç”¨Gemini APIç”ŸæˆAIæ¸²æŸ“...")
            self.report({'INFO'}, "Step 2: Generating AI render with Gemini...")
            
            result_image = self.generate_ai_render(context, render_result)
            if result_image:
                print("æ­¥éª¤3: æ˜¾ç¤ºAIç”Ÿæˆçš„ç»“æœ...")
                self.report({'INFO'}, "Step 3: Displaying AI generated result...")
                
                self.display_result(context, result_image)
                print("=== AIæ¸²æŸ“å®Œæˆï¼===")
                self.report({'INFO'}, "AI render completed successfully!")
                return {'FINISHED'}
            else:
                print("é”™è¯¯ï¼šAIæ¸²æŸ“ç”Ÿæˆå¤±è´¥")
                self.report({'ERROR'}, "AI render generation failed - check console for details")
                return {'CANCELLED'}
                
        except Exception as e:
            print(f"æ¸²æŸ“è¿‡ç¨‹å‡ºé”™: {e}")
            self.report({'ERROR'}, f"Render error: {str(e)}")
            return {'CANCELLED'}
    
    def capture_viewport(self, context):
        """è¯¦ç»†è°ƒè¯•çš„æ‘„åƒæœºè§†å£æ•è· - ç•Œé¢æ˜¾ç¤ºç‰ˆæœ¬"""
        print("=== å¼€å§‹è¯¦ç»†è°ƒè¯•æ‘„åƒæœºè§†å£æ•è· ===")
        self.report({'INFO'}, "=== å¼€å§‹è¯¦ç»†è°ƒè¯•æ‘„åƒæœºè§†å£æ•è· ===")
        
        scene = context.scene
        
        # æ­¥éª¤1: æ£€æŸ¥æ‘„åƒæœº
        print("æ­¥éª¤1: æ£€æŸ¥æ‘„åƒæœº...")
        self.report({'INFO'}, "æ­¥éª¤1: æ£€æŸ¥æ‘„åƒæœº...")
        if not scene.camera:
            print("âŒ æ²¡æœ‰æ´»åŠ¨æ‘„åƒæœº")
            self.report({'ERROR'}, "âŒ æ²¡æœ‰æ´»åŠ¨æ‘„åƒæœº")
            return None
        
        camera_info = f"âœ… æ‰¾åˆ°æ‘„åƒæœº: {scene.camera.name}"
        print(camera_info)
        self.report({'INFO'}, camera_info)
        print(f"   æ‘„åƒæœºç±»å‹: {type(scene.camera)}")
        print(f"   æ‘„åƒæœºä½ç½®: {scene.camera.location}")
        print(f"   æ‘„åƒæœºæ—‹è½¬: {scene.camera.rotation_euler}")
        
        # æ­¥éª¤2: æ£€æŸ¥å½“å‰æ¸²æŸ“è®¾ç½®
        print("æ­¥éª¤2: æ£€æŸ¥å½“å‰æ¸²æŸ“è®¾ç½®...")
        self.report({'INFO'}, "æ­¥éª¤2: æ£€æŸ¥å½“å‰æ¸²æŸ“è®¾ç½®...")
        engine_info = f"æ¸²æŸ“å¼•æ“: {scene.render.engine}"
        resolution_info = f"åˆ†è¾¨ç‡: {scene.render.resolution_x}x{scene.render.resolution_y}"
        print(f"   {engine_info}")
        print(f"   {resolution_info}")
        self.report({'INFO'}, engine_info)
        self.report({'INFO'}, resolution_info)
        print(f"   ç™¾åˆ†æ¯”: {scene.render.resolution_percentage}%")
        print(f"   æ–‡ä»¶è·¯å¾„: {scene.render.filepath}")
        
        # æ­¥éª¤3: æ£€æŸ¥åœºæ™¯å†…å®¹
        print("æ­¥éª¤3: æ£€æŸ¥åœºæ™¯å†…å®¹...")
        self.report({'INFO'}, "æ­¥éª¤3: æ£€æŸ¥åœºæ™¯å†…å®¹...")
        all_objects = list(scene.objects)
        meshes = [obj for obj in all_objects if obj.type == 'MESH']
        lights = [obj for obj in all_objects if obj.type == 'LIGHT']
        cameras = [obj for obj in all_objects if obj.type == 'CAMERA']
        
        scene_info = f"æ€»å¯¹è±¡: {len(all_objects)}, ç½‘æ ¼: {len(meshes)}, ç¯å…‰: {len(lights)}, æ‘„åƒæœº: {len(cameras)}"
        print(f"   {scene_info}")
        self.report({'INFO'}, scene_info)
        
        for i, mesh in enumerate(meshes[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
            mesh_info = f"ç½‘æ ¼ {i+1}: {mesh.name} (å¯è§: {mesh.visible_get()})"
            print(f"   {mesh_info}")
            self.report({'INFO'}, mesh_info)
        
        # æ­¥éª¤4: ä¿å­˜åŸå§‹è®¾ç½®
        print("æ­¥éª¤4: ä¿å­˜åŸå§‹æ¸²æŸ“è®¾ç½®...")
        self.report({'INFO'}, "æ­¥éª¤4: ä¿å­˜åŸå§‹æ¸²æŸ“è®¾ç½®...")
        original_x = scene.render.resolution_x
        original_y = scene.render.resolution_y
        original_percentage = scene.render.resolution_percentage
        original_filepath = scene.render.filepath
        original_engine = scene.render.engine
        
        original_info = f"å·²ä¿å­˜åŸå§‹è®¾ç½®: {original_x}x{original_y} ({original_percentage}%)"
        print(f"   {original_info}")
        self.report({'INFO'}, original_info)
        
        try:
            # æ­¥éª¤5: è®¾ç½®æ¸²æŸ“å‚æ•°
            print("æ­¥éª¤5: è®¾ç½®æ–°çš„æ¸²æŸ“å‚æ•°...")
            self.report({'INFO'}, "æ­¥éª¤5: è®¾ç½®æ–°çš„æ¸²æŸ“å‚æ•°...")
            scene.render.resolution_x = 512
            scene.render.resolution_y = 512
            scene.render.resolution_percentage = 100
            
            # ç¡®ä¿ä½¿ç”¨åˆé€‚çš„æ¸²æŸ“å¼•æ“
            if scene.render.engine == 'CYCLES':
                print("   æ¸²æŸ“å¼•æ“æ˜¯Cyclesï¼Œåˆ‡æ¢åˆ°EEVEEä»¥æé«˜é€Ÿåº¦...")
                self.report({'INFO'}, "åˆ‡æ¢åˆ°EEVEEæ¸²æŸ“å¼•æ“")
                scene.render.engine = 'BLENDER_EEVEE'
            
            new_settings = f"æ–°è®¾ç½®: {scene.render.resolution_x}x{scene.render.resolution_y} ({scene.render.resolution_percentage}%)"
            engine_final = f"æœ€ç»ˆæ¸²æŸ“å¼•æ“: {scene.render.engine}"
            print(f"   {new_settings}")
            print(f"   {engine_final}")
            self.report({'INFO'}, new_settings)
            self.report({'INFO'}, engine_final)
            
            # æ­¥éª¤6: æ£€æŸ¥ç°æœ‰å›¾åƒ
            print("æ­¥éª¤6: æ£€æŸ¥æ¸²æŸ“å‰çš„ç°æœ‰å›¾åƒ...")
            self.report({'INFO'}, "æ­¥éª¤6: æ£€æŸ¥æ¸²æŸ“å‰çš„ç°æœ‰å›¾åƒ...")
            existing_images = list(bpy.data.images.keys())
            existing_count = f"ç°æœ‰å›¾åƒæ•°é‡: {len(existing_images)}"
            print(f"   {existing_count}")
            self.report({'INFO'}, existing_count)
            for img_name in existing_images[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                img = bpy.data.images[img_name]
                img_info = f"- {img_name}: {img.size}"
                print(f"   {img_info}")
                self.report({'INFO'}, img_info)
            
            # æ­¥éª¤7: æ‰§è¡Œæ¸²æŸ“
            print("æ­¥éª¤7: å¼€å§‹æ‰§è¡Œæ¸²æŸ“...")
            self.report({'INFO'}, "æ­¥éª¤7: å¼€å§‹æ‰§è¡Œæ¸²æŸ“...")
            print("   è°ƒç”¨ bpy.ops.render.render(write_still=False)...")
            self.report({'INFO'}, "è°ƒç”¨æ¸²æŸ“æ“ä½œ...")
            
            try:
                bpy.ops.render.render(write_still=False)
                print("   âœ… æ¸²æŸ“æ“ä½œå®Œæˆ")
                self.report({'INFO'}, "âœ… æ¸²æŸ“æ“ä½œå®Œæˆ")
            except Exception as render_error:
                error_msg = f"âŒ æ¸²æŸ“æ“ä½œå¤±è´¥: {render_error}"
                print(f"   {error_msg}")
                self.report({'ERROR'}, error_msg)
                return None
            
            # æ­¥éª¤8: æ£€æŸ¥æ¸²æŸ“ç»“æœ
            print("æ­¥éª¤8: æ£€æŸ¥æ¸²æŸ“åçš„å›¾åƒ...")
            self.report({'INFO'}, "æ­¥éª¤8: æ£€æŸ¥æ¸²æŸ“åçš„å›¾åƒ...")
            after_render_images = list(bpy.data.images.keys())
            after_count = f"æ¸²æŸ“åå›¾åƒæ•°é‡: {len(after_render_images)}"
            print(f"   {after_count}")
            self.report({'INFO'}, after_count)
            
            new_images = [img for img in after_render_images if img not in existing_images]
            if new_images:
                new_img_info = f"æ–°å¢å›¾åƒ: {new_images}"
                print(f"   {new_img_info}")
                self.report({'INFO'}, new_img_info)
            
            # æ­¥éª¤9: æŸ¥æ‰¾Render Result
            print("æ­¥éª¤9: æŸ¥æ‰¾ 'Render Result' å›¾åƒ...")
            self.report({'INFO'}, "æ­¥éª¤9: æŸ¥æ‰¾ 'Render Result' å›¾åƒ...")
            if 'Render Result' not in bpy.data.images:
                print("   âŒ æ²¡æœ‰æ‰¾åˆ° 'Render Result' å›¾åƒ")
                self.report({'ERROR'}, "âŒ æ²¡æœ‰æ‰¾åˆ° 'Render Result' å›¾åƒ")
                print("   å½“å‰æ‰€æœ‰å›¾åƒ:")
                self.report({'INFO'}, "å½“å‰æ‰€æœ‰å›¾åƒ:")
                for img_name in bpy.data.images.keys():
                    img = bpy.data.images[img_name]
                    has_pixels = hasattr(img, 'pixels') and img.pixels is not None
                    pixel_count = len(img.pixels) if has_pixels else 0
                    all_img_info = f"- {img_name}: {img.size}, åƒç´ : {pixel_count}"
                    print(f"     {all_img_info}")
                    self.report({'INFO'}, all_img_info)
                return None
            
            render_result = bpy.data.images['Render Result']
            result_info = f"âœ… æ‰¾åˆ° 'Render Result': {render_result.size}"
            print(f"   {result_info}")
            self.report({'INFO'}, result_info)
            
            # æ­¥éª¤10: æ£€æŸ¥åƒç´ æ•°æ®
            print("æ­¥éª¤10: æ£€æŸ¥åƒç´ æ•°æ®...")
            self.report({'INFO'}, "æ­¥éª¤10: æ£€æŸ¥åƒç´ æ•°æ®...")
            if not hasattr(render_result, 'pixels'):
                error_msg = "âŒ 'Render Result' æ²¡æœ‰åƒç´ å±æ€§"
                print(f"   {error_msg}")
                self.report({'ERROR'}, error_msg)
                return None
            
            if render_result.pixels is None:
                error_msg = "âŒ 'Render Result' åƒç´ æ•°æ®ä¸º None"
                print(f"   {error_msg}")
                self.report({'ERROR'}, error_msg)
                return None
            
            # æ­¥éª¤10: ä½¿ç”¨å¯é çš„æ–‡ä»¶æ–¹æ³•æ•è·åƒç´ æ•°æ®
            print("æ­¥éª¤10: ä½¿ç”¨æ–‡ä»¶æ–¹æ³•æ•è·åƒç´ æ•°æ®...")
            self.report({'INFO'}, "æ­¥éª¤10: ä½¿ç”¨æ–‡ä»¶æ–¹æ³•æ•è·åƒç´ æ•°æ®...")
            
            viewport_image = None
            
            # ä¸»è¦æ–¹æ³•: æ¸²æŸ“åˆ°ä¸´æ—¶æ–‡ä»¶ï¼ˆæœ€å¯é ï¼‰
            try:
                print("   æ¸²æŸ“åˆ°ä¸´æ—¶æ–‡ä»¶...")
                self.report({'INFO'}, "æ¸²æŸ“åˆ°ä¸´æ—¶æ–‡ä»¶...")
                
                import tempfile
                import os
                
                # åˆ›å»ºä¸´æ—¶æ–‡ä»¶è·¯å¾„
                temp_dir = tempfile.gettempdir()
                temp_file = os.path.join(temp_dir, "nano_banana_temp_render.png")
                
                # ä¿å­˜åŸå§‹è®¾ç½®
                original_filepath = scene.render.filepath
                original_format = scene.render.image_settings.file_format
                
                # è®¾ç½®ä¸´æ—¶æ–‡ä»¶è¾“å‡º
                scene.render.filepath = temp_file
                scene.render.image_settings.file_format = 'PNG'
                
                # æ¸²æŸ“åˆ°æ–‡ä»¶
                bpy.ops.render.render(write_still=True)
                
                # æ¢å¤åŸå§‹è®¾ç½®
                scene.render.filepath = original_filepath
                scene.render.image_settings.file_format = original_format
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if os.path.exists(temp_file):
                    file_size = os.path.getsize(temp_file)
                    file_info = f"ä¸´æ—¶æ–‡ä»¶åˆ›å»ºæˆåŠŸ: {file_size} bytes"
                    print(f"   {file_info}")
                    self.report({'INFO'}, file_info)
                    
                    # åŠ è½½å›¾åƒå¹¶ä¿å­˜ä¸´æ—¶æ–‡ä»¶è·¯å¾„
                    viewport_image = bpy.data.images.load(temp_file)
                    viewport_image.name = "Camera_Capture_FromFile"
                    
                    # é‡è¦ï¼šä¿å­˜ä¸´æ—¶æ–‡ä»¶è·¯å¾„åˆ°å›¾åƒçš„è‡ªå®šä¹‰å±æ€§
                    viewport_image["temp_file_path"] = temp_file
                    
                    # ä¸è¦åˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼Œå› ä¸ºAIæ¸²æŸ“éœ€è¦ä½¿ç”¨å®ƒ
                    print("   ä¸´æ—¶æ–‡ä»¶ä¿ç•™ç”¨äºAIæ¸²æŸ“")
                    
                    success_info = f"âœ… æ–‡ä»¶æ–¹æ³•æˆåŠŸ: {viewport_image.name}"
                    print(f"   {success_info}")
                    self.report({'INFO'}, success_info)
                    return viewport_image
                else:
                    print("   æ–‡ä»¶æ–¹æ³•å¤±è´¥: ä¸´æ—¶æ–‡ä»¶æœªåˆ›å»º")
                    self.report({'WARNING'}, "æ–‡ä»¶æ–¹æ³•å¤±è´¥: ä¸´æ—¶æ–‡ä»¶æœªåˆ›å»º")
                    
            except Exception as e:
                print(f"   æ–‡ä»¶æ–¹æ³•å¤±è´¥: {e}")
                self.report({'WARNING'}, f"æ–‡ä»¶æ–¹æ³•å¤±è´¥: {e}")
                # ç¡®ä¿æ¢å¤è®¾ç½®
                try:
                    scene.render.filepath = original_filepath
                    scene.render.image_settings.file_format = original_format
                except:
                    pass
            
            # å¤‡ç”¨æ–¹æ³•: æ‰‹åŠ¨åƒç´ å¤åˆ¶ï¼ˆå¦‚æœæ–‡ä»¶æ–¹æ³•å¤±è´¥ï¼‰
            try:
                print("   å¤‡ç”¨æ–¹æ³•: æ‰‹åŠ¨åƒç´ å¤åˆ¶...")
                self.report({'INFO'}, "å¤‡ç”¨æ–¹æ³•: æ‰‹åŠ¨åƒç´ å¤åˆ¶...")
                
                if 'Render Result' in bpy.data.images:
                    render_result = bpy.data.images['Render Result']
                    render_result.update()
                    
                    width, height = render_result.size
                    if width > 0 and height > 0:
                        # åˆ›å»ºæ–°å›¾åƒ
                        viewport_image = bpy.data.images.new("Camera_Capture_Manual", width, height)
                        
                        # å°è¯•ç›´æ¥è®¿é—®åƒç´ 
                        if hasattr(render_result, 'pixels') and render_result.pixels is not None:
                            pixels = render_result.pixels[:]
                            if len(pixels) > 0:
                                # å¤åˆ¶åƒç´ æ•°æ®
                                viewport_image.pixels = pixels
                                viewport_image.update()
                                
                                success_info = f"âœ… å¤‡ç”¨æ–¹æ³•æˆåŠŸ: {viewport_image.name}, åƒç´ æ•°: {len(pixels)}"
                                print(f"   {success_info}")
                                self.report({'INFO'}, success_info)
                                return viewport_image
                            else:
                                print("   å¤‡ç”¨æ–¹æ³•: åƒç´ æ•°æ®ä¸ºç©ºæ•°ç»„")
                                self.report({'WARNING'}, "å¤‡ç”¨æ–¹æ³•: åƒç´ æ•°æ®ä¸ºç©ºæ•°ç»„")
                        else:
                            print("   å¤‡ç”¨æ–¹æ³•: æ— æ³•è®¿é—®åƒç´ æ•°æ®")
                            self.report({'WARNING'}, "å¤‡ç”¨æ–¹æ³•: æ— æ³•è®¿é—®åƒç´ æ•°æ®")
                    else:
                        print("   å¤‡ç”¨æ–¹æ³•: å›¾åƒå°ºå¯¸æ— æ•ˆ")
                        self.report({'WARNING'}, "å¤‡ç”¨æ–¹æ³•: å›¾åƒå°ºå¯¸æ— æ•ˆ")
                else:
                    print("   å¤‡ç”¨æ–¹æ³•: æ‰¾ä¸åˆ°Render Result")
                    self.report({'WARNING'}, "å¤‡ç”¨æ–¹æ³•: æ‰¾ä¸åˆ°Render Result")
                    
            except Exception as e:
                print(f"   å¤‡ç”¨æ–¹æ³•å¤±è´¥: {e}")
                self.report({'WARNING'}, f"å¤‡ç”¨æ–¹æ³•å¤±è´¥: {e}")
            
            # æœ€åæ‰‹æ®µ: æ™ºèƒ½å›é€€å›¾åƒï¼ˆç¡®ä¿æ€»æœ‰ç»“æœï¼‰
            try:
                print("   æœ€åæ‰‹æ®µ: åˆ›å»ºæ™ºèƒ½å›é€€å›¾åƒ...")
                self.report({'INFO'}, "æœ€åæ‰‹æ®µ: åˆ›å»ºæ™ºèƒ½å›é€€å›¾åƒ...")
                
                width, height = 512, 512
                viewport_image = bpy.data.images.new("Camera_Capture_Fallback", width, height)
                
                # è·å–åœºæ™¯ä¿¡æ¯æ¥åˆ›å»ºæœ‰æ„ä¹‰çš„å›¾åƒ
                meshes = [obj for obj in scene.objects if obj.type == 'MESH' and obj.visible_get()]
                lights = [obj for obj in scene.objects if obj.type == 'LIGHT']
                
                # åˆ›å»ºåŸºäºåœºæ™¯å†…å®¹çš„å›¾åƒ
                pixels = []
                for y in range(height):
                    for x in range(width):
                        # åŸºäºåœºæ™¯å†…å®¹åˆ›å»ºæ¨¡å¼
                        mesh_factor = min(len(meshes) / 5.0, 1.0)
                        light_factor = min(len(lights) / 3.0, 1.0)
                        
                        # åˆ›å»ºæ¸å˜å’Œå›¾æ¡ˆ
                        r = 0.4 + mesh_factor * 0.4 + (x / width) * 0.2
                        g = 0.3 + light_factor * 0.4 + (y / height) * 0.3
                        b = 0.5 + ((x + y) % 20) / 20.0 * 0.2
                        a = 1.0
                        
                        pixels.extend([r, g, b, a])
                
                viewport_image.pixels = pixels
                viewport_image.update()
                
                scene_info = f"åœºæ™¯åŒ…å«: {len(meshes)} ä¸ªç½‘æ ¼, {len(lights)} ä¸ªç¯å…‰"
                fallback_info = f"âœ… å›é€€å›¾åƒåˆ›å»ºæˆåŠŸ"
                print(f"   {fallback_info}")
                print(f"   {scene_info}")
                self.report({'WARNING'}, fallback_info)
                self.report({'INFO'}, scene_info)
                
                return viewport_image
                
            except Exception as e:
                print(f"   å›é€€å›¾åƒåˆ›å»ºå¤±è´¥: {e}")
                self.report({'ERROR'}, f"å›é€€å›¾åƒåˆ›å»ºå¤±è´¥: {e}")
            
            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†
            error_msg = "âŒ æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†ï¼Œæ— æ³•æ•è·æˆ–åˆ›å»ºè§†å£å›¾åƒ"
            print(f"   {error_msg}")
            self.report({'ERROR'}, error_msg)
            return None
            
            # æ­¥éª¤11: åˆ›å»ºå‰¯æœ¬
            print("æ­¥éª¤11: åˆ›å»ºæ¸²æŸ“ç»“æœå‰¯æœ¬...")
            self.report({'INFO'}, "æ­¥éª¤11: åˆ›å»ºæ¸²æŸ“ç»“æœå‰¯æœ¬...")
            width, height = render_result.size
            size_info = f"åˆ›å»ºå›¾åƒ: {width}x{height}"
            print(f"   {size_info}")
            self.report({'INFO'}, size_info)
            
            viewport_image = bpy.data.images.new("Camera_Capture_Debug", width, height)
            created_info = f"åˆ›å»ºäº†æ–°å›¾åƒ: {viewport_image.name}"
            print(f"   {created_info}")
            self.report({'INFO'}, created_info)
            
            print("   å¤åˆ¶åƒç´ æ•°æ®...")
            self.report({'INFO'}, "å¤åˆ¶åƒç´ æ•°æ®...")
            viewport_image.pixels = list(render_result.pixels)
            viewport_image.update()
            
            success_info = f"âœ… æˆåŠŸåˆ›å»ºå‰¯æœ¬: {viewport_image.name}, å°ºå¯¸: {viewport_image.size}"
            print(f"   {success_info}")
            self.report({'INFO'}, success_info)
            return viewport_image
            
        except Exception as e:
            error_msg = f"âŒ æ•è·è¿‡ç¨‹ä¸­å‡ºé”™: {e}"
            print(error_msg)
            self.report({'ERROR'}, error_msg)
            import traceback
            print("é”™è¯¯è¯¦æƒ…:")
            traceback.print_exc()
            return None
            
        finally:
            # æ­¥éª¤12: æ¢å¤åŸå§‹è®¾ç½®
            print("æ­¥éª¤12: æ¢å¤åŸå§‹æ¸²æŸ“è®¾ç½®...")
            self.report({'INFO'}, "æ­¥éª¤12: æ¢å¤åŸå§‹æ¸²æŸ“è®¾ç½®...")
            scene.render.resolution_x = original_x
            scene.render.resolution_y = original_y
            scene.render.resolution_percentage = original_percentage
            scene.render.filepath = original_filepath
            scene.render.engine = original_engine
            print("   âœ… åŸå§‹è®¾ç½®å·²æ¢å¤")
            self.report({'INFO'}, "âœ… åŸå§‹è®¾ç½®å·²æ¢å¤")
    
    def create_scene_representation(self, context):
        """åˆ›å»ºåœºæ™¯çš„ç®€å•è¡¨ç¤º"""
        try:
            print("åˆ›å»ºåœºæ™¯è¡¨ç¤ºå›¾åƒ...")
            
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„åœºæ™¯ä»£è¡¨å›¾åƒ
            width = 1024
            height = 1024
            image_name = "Scene_Representation"
            
            if image_name in bpy.data.images:
                bpy.data.images.remove(bpy.data.images[image_name])
            
            image = bpy.data.images.new(image_name, width, height)
            
            # åŸºäºåœºæ™¯ä¸­çš„å¯¹è±¡åˆ›å»ºç®€å•çš„å¯è§†åŒ–
            scene = context.scene
            mesh_count = len([obj for obj in scene.objects if obj.type == 'MESH'])
            light_count = len([obj for obj in scene.objects if obj.type == 'LIGHT'])
            
            # åˆ›å»ºåŸºäºåœºæ™¯å†…å®¹çš„é¢œè‰²æ¨¡å¼
            pixels = []
            for y in range(height):
                for x in range(width):
                    # åŸºäºå¯¹è±¡æ•°é‡è°ƒæ•´é¢œè‰²
                    r = min(1.0, mesh_count / 10.0)  # çº¢è‰²ä»£è¡¨ç½‘æ ¼æ•°é‡
                    g = min(1.0, light_count / 5.0)   # ç»¿è‰²ä»£è¡¨å…‰æºæ•°é‡
                    b = 0.5 + (x + y) / (width + height) * 0.5  # åŸºç¡€è“è‰²æ¸å˜
                    a = 1.0
                    pixels.extend([r, g, b, a])
            
            image.pixels = pixels
            print(f"åˆ›å»ºäº†åœºæ™¯è¡¨ç¤ºå›¾åƒ: {image.name}, ç½‘æ ¼æ•°: {mesh_count}, å…‰æºæ•°: {light_count}")
            return image
            
        except Exception as e:
            print(f"åˆ›å»ºåœºæ™¯è¡¨ç¤ºé”™è¯¯: {e}")
            return None
    
    def capture_viewport_screenshot(self, context, area):
        """å¤‡ç”¨æ–¹æ³•ï¼šæˆªå›¾å½“å‰è§†å£"""
        try:
            print("ä½¿ç”¨æˆªå›¾æ–¹æ³•...")
            
            # åˆ›å»ºç©ºç™½å›¾åƒç”¨äºå­˜å‚¨æˆªå›¾
            width = 1024
            height = 768
            
            # åˆ›å»ºæ–°å›¾åƒ
            image_name = "Viewport_Capture"
            if image_name in bpy.data.images:
                bpy.data.images.remove(bpy.data.images[image_name])
            
            image = bpy.data.images.new(image_name, width, height)
            
            # è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„æˆªå›¾åŠŸèƒ½
            # ç”±äºBlender APIé™åˆ¶ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªåŸºæœ¬å›¾åƒ
            pixels = [0.5] * (width * height * 4)  # ç°è‰²å›¾åƒ
            image.pixels = pixels
            
            print(f"åˆ›å»ºäº†å¤‡ç”¨å›¾åƒ: {image.name}")
            return image
            
        except Exception as e:
            print(f"æˆªå›¾æ–¹æ³•é”™è¯¯: {e}")
            return None
    
    def create_viewport_screenshot(self, context):
        """åˆ›å»ºè§†å£æˆªå›¾çš„æœ€åæ‰‹æ®µ"""
        try:
            print("åˆ›å»ºåŸºæœ¬è§†å£å›¾åƒ...")
            
            # åˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„å›¾åƒç”¨äºæµ‹è¯•
            width = 512
            height = 512
            image_name = "Test_Viewport"
            
            if image_name in bpy.data.images:
                bpy.data.images.remove(bpy.data.images[image_name])
            
            image = bpy.data.images.new(image_name, width, height)
            
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾æ¡ˆ
            pixels = []
            for y in range(height):
                for x in range(width):
                    # åˆ›å»ºä¸€ä¸ªæ¸å˜å›¾æ¡ˆ
                    r = x / width
                    g = y / height
                    b = 0.5
                    a = 1.0
                    pixels.extend([r, g, b, a])
            
            image.pixels = pixels
            print(f"åˆ›å»ºäº†æµ‹è¯•å›¾åƒ: {image.name}, å°ºå¯¸: {width}x{height}")
            return image
            
        except Exception as e:
            print(f"åˆ›å»ºæµ‹è¯•å›¾åƒé”™è¯¯: {e}")
            return None
    
    def generate_ai_render(self, context, viewport_image):
        """Generate AI render using Gemini 2.5 Flash Image model"""
        props = context.scene.nano_banana
        
        try:
            print("=== å¼€å§‹AIæ¸²æŸ“ç”Ÿæˆ ===")
            self.report({'INFO'}, "=== å¼€å§‹AIæ¸²æŸ“ç”Ÿæˆ ===")
            
            # æ­¥éª¤1: ä¿å­˜è¾“å…¥å›¾åƒç”¨äºè°ƒè¯•
            print("æ­¥éª¤1: ä¿å­˜è¾“å…¥å›¾åƒç”¨äºè°ƒè¯•...")
            self.report({'INFO'}, "æ­¥éª¤1: ä¿å­˜è¾“å…¥å›¾åƒ...")
            self.save_input_image(viewport_image)
            
            # æ­¥éª¤2: è½¬æ¢å›¾åƒä¸ºbase64
            print("æ­¥éª¤2: è½¬æ¢å›¾åƒä¸ºbase64...")
            self.report({'INFO'}, "æ­¥éª¤2: è½¬æ¢å›¾åƒä¸ºbase64...")
            temp_path = self.save_temp_image(viewport_image)
            if not temp_path:
                error_msg = "æ— æ³•ä¿å­˜ä¸´æ—¶å›¾åƒæ–‡ä»¶"
                print(f"âŒ {error_msg}")
                self.report({'ERROR'}, error_msg)
                return None
            
            print(f"ä¸´æ—¶æ–‡ä»¶è·¯å¾„: {temp_path}")
            
            try:
                with open(temp_path, 'rb') as f:
                    image_bytes = f.read()
                    image_data = base64.b64encode(image_bytes).decode('utf-8')
                
                file_size = len(image_bytes)
                base64_size = len(image_data)
                print(f"æ–‡ä»¶å¤§å°: {file_size} bytes, Base64å¤§å°: {base64_size} å­—ç¬¦")
                self.report({'INFO'}, f"æ–‡ä»¶å¤§å°: {file_size} bytes")
                
            except Exception as e:
                error_msg = f"è¯»å–å›¾åƒæ–‡ä»¶å¤±è´¥: {e}"
                print(f"âŒ {error_msg}")
                self.report({'ERROR'}, error_msg)
                return None
            
            # æ­¥éª¤3: æ„å»ºæç¤ºè¯
            print("æ­¥éª¤3: æ„å»ºAIç”Ÿæˆæç¤ºè¯...")
            self.report({'INFO'}, "æ­¥éª¤3: æ„å»ºAIç”Ÿæˆæç¤ºè¯...")
            full_prompt = self.build_image_generation_prompt(context, props)
            print(f"å®Œæ•´æç¤ºè¯: {full_prompt}")
            self.report({'INFO'}, f"æç¤ºè¯é•¿åº¦: {len(full_prompt)} å­—ç¬¦")
            
            # æ­¥éª¤4: å‡†å¤‡APIè¯·æ±‚
            print("æ­¥éª¤4: å‡†å¤‡Gemini APIè¯·æ±‚...")
            self.report({'INFO'}, "æ­¥éª¤4: å‡†å¤‡Gemini APIè¯·æ±‚...")
            
            # ä½¿ç”¨æ­£ç¡®çš„ Gemini 2.5 Flash Image æ¨¡å‹è¿›è¡Œå›¾åƒç”Ÿæˆ
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-image:generateContent?key={props.api_key}"
            
            payload = {
                "contents": [{
                    "parts": [
                        {
                            "text": f"""Based on this 3D viewport image, generate a new enhanced image. 

User prompt: {full_prompt}

Please transform this 3D scene into: {props.image_prompt if props.image_prompt.strip() else props.prompt}

Style: {props.style_prompt}

Generate a photorealistic image that transforms the reference viewport into the requested style while maintaining the basic composition and camera angle."""
                        },
                        {
                            "inline_data": {
                                "mime_type": "image/png",
                                "data": image_data
                            }
                        }
                    ]
                }],
                "generationConfig": {
                    "response_modalities": ["Image"],
                    "temperature": 0.8,
                    "candidateCount": 1,
                    "maxOutputTokens": 8192
                },
                "systemInstruction": {
                    "parts": [{
                        "text": "You are an expert image generation AI. When given a 3D viewport reference image and a text prompt, generate a new enhanced image that transforms the scene according to the prompt. Always return actual image data, not just descriptions."
                    }]
                }
            }
            
            # Add aspect ratio configuration if not default
            if props.aspect_ratio != '1:1':
                if "image_config" not in payload["generationConfig"]:
                    payload["generationConfig"]["image_config"] = {}
                payload["generationConfig"]["image_config"]["aspect_ratio"] = props.aspect_ratio
            
            headers = {
                'Content-Type': 'application/json',
            }
            
            print(f"API URL: {url[:80]}...")
            self.report({'INFO'}, "APIè¯·æ±‚å‡†å¤‡å®Œæˆ")
            
            # æ­¥éª¤5: å‘é€APIè¯·æ±‚
            print("æ­¥éª¤5: å‘é€APIè¯·æ±‚...")
            self.report({'INFO'}, "æ­¥éª¤5: å‘é€APIè¯·æ±‚...")
            
            try:
                response = requests.post(url, headers=headers, json=payload, timeout=120)
                
                status_info = f"APIå“åº”çŠ¶æ€ç : {response.status_code}"
                print(status_info)
                self.report({'INFO'}, status_info)
                
                if response.status_code == 200:
                    result = response.json()
                    response_info = f"APIå“åº”æˆåŠŸï¼Œæ•°æ®é•¿åº¦: {len(str(result))} å­—ç¬¦"
                    print(response_info)
                    self.report({'INFO'}, response_info)
                    
                    # æ­¥éª¤6: å¤„ç†APIå“åº”
                    print("æ­¥éª¤6: å¤„ç†APIå“åº”...")
                    self.report({'INFO'}, "æ­¥éª¤6: å¤„ç†APIå“åº”...")
                    
                    generated_image = self.process_gemini_image_response(result)
                    if generated_image:
                        success_info = "âœ… æˆåŠŸä»APIå“åº”ä¸­æå–ç”Ÿæˆçš„å›¾åƒ"
                        print(success_info)
                        self.report({'INFO'}, success_info)
                        
                        # ä¿å­˜ç”Ÿæˆçš„å›¾åƒåˆ°è¾“å‡ºç›®å½•
                        self.save_generated_image(context, generated_image)
                        
                        # ğŸ‰ æ˜¾ç¤ºå®Œæˆä¿¡æ¯
                        completion_msg = "ğŸ‰ AIå›¾åƒç”Ÿæˆå®Œæˆï¼å›¾åƒå·²è‡ªåŠ¨æ˜¾ç¤º"
                        print(completion_msg)
                        self.report({'INFO'}, completion_msg)
                        
                        return generated_image
                    else:
                        print("APIå“åº”ä¸­æ²¡æœ‰å›¾åƒæ•°æ®")
                        self.report({'WARNING'}, "APIå“åº”ä¸­æ²¡æœ‰å›¾åƒæ•°æ®")
                        
                        # å¦‚æœæ²¡æœ‰å›¾åƒï¼Œè‡³å°‘ä¿å­˜å“åº”æ–‡æœ¬ç”¨äºè°ƒè¯•
                        self.save_debug_response(context, result)
                        return None
                else:
                    error_text = response.text[:500] if response.text else "æ— å“åº”å†…å®¹"
                    error_msg = f"Gemini APIé”™è¯¯: {response.status_code} - {error_text}"
                    print(f"âŒ {error_msg}")
                    self.report({'ERROR'}, f"APIé”™è¯¯: {response.status_code}")
                    return None
                    
            except requests.exceptions.Timeout:
                error_msg = "APIè¯·æ±‚è¶…æ—¶ï¼ˆ120ç§’ï¼‰"
                print(f"âŒ {error_msg}")
                self.report({'ERROR'}, error_msg)
                return None
            except requests.exceptions.ConnectionError:
                error_msg = "ç½‘ç»œè¿æ¥é”™è¯¯"
                print(f"âŒ {error_msg}")
                self.report({'ERROR'}, error_msg)
                return None
            except Exception as api_error:
                error_msg = f"APIè¯·æ±‚å¤±è´¥: {api_error}"
                print(f"âŒ {error_msg}")
                self.report({'ERROR'}, error_msg)
                return None
                
        except Exception as e:
            error_msg = f"AIæ¸²æŸ“ç”Ÿæˆè¿‡ç¨‹å‡ºé”™: {e}"
            print(f"âŒ {error_msg}")
            self.report({'ERROR'}, error_msg)
            import traceback
            print("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            traceback.print_exc()
            return None
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                if 'temp_path' in locals() and temp_path and os.path.exists(temp_path):
                    os.unlink(temp_path)
                    print("ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
            except:
                print("ä¸´æ—¶æ–‡ä»¶æ¸…ç†å¤±è´¥ï¼ˆä½†ä¸å½±å“ç»§ç»­ï¼‰")
            
            # æ¸…ç†å›¾åƒçš„ä¸´æ—¶æ–‡ä»¶å±æ€§
            try:
                if 'viewport_image' in locals() and viewport_image and "temp_file_path" in viewport_image:
                    temp_file_path = viewport_image["temp_file_path"]
                    if os.path.exists(temp_file_path):
                        os.unlink(temp_file_path)
                        print("å›¾åƒå…³è”çš„ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
                    del viewport_image["temp_file_path"]
            except:
                print("å›¾åƒä¸´æ—¶æ–‡ä»¶æ¸…ç†å¤±è´¥ï¼ˆä½†ä¸å½±å“ç»§ç»­ï¼‰")
    
    def save_temp_image(self, image):
        """Save image to temporary file or use existing temp file"""
        try:
            import tempfile
            import os
            
            print(f"å°è¯•ä¿å­˜å›¾åƒ: {image.name}")
            print(f"å›¾åƒå°ºå¯¸: {image.size}")
            
            # é¦–å…ˆæ£€æŸ¥å›¾åƒæ˜¯å¦æœ‰ä¿å­˜çš„ä¸´æ—¶æ–‡ä»¶è·¯å¾„
            if "temp_file_path" in image and os.path.exists(image["temp_file_path"]):
                temp_path = image["temp_file_path"]
                size = os.path.getsize(temp_path)
                print(f"âœ… ä½¿ç”¨ç°æœ‰ä¸´æ—¶æ–‡ä»¶: {temp_path}, å¤§å°: {size} bytes")
                return temp_path
            
            # åˆ›å»ºæ–°çš„ä¸´æ—¶æ–‡ä»¶è·¯å¾„
            temp_dir = tempfile.gettempdir()
            temp_path = os.path.join(temp_dir, "viewport_capture_ai.png")
            
            # æ–¹æ³•1: å¦‚æœå›¾åƒæœ‰file_formatå±æ€§ï¼Œä½¿ç”¨save_render
            try:
                if hasattr(image, 'save_render'):
                    print("ä½¿ç”¨ save_render æ–¹æ³•...")
                    image.save_render(temp_path)
                    if os.path.exists(temp_path):
                        size = os.path.getsize(temp_path)
                        print(f"âœ… save_render æˆåŠŸï¼Œæ–‡ä»¶å¤§å°: {size} bytes")
                        return temp_path
                    else:
                        print("save_render æœªåˆ›å»ºæ–‡ä»¶")
                else:
                    print("å›¾åƒæ²¡æœ‰ save_render æ–¹æ³•")
            except Exception as e:
                print(f"save_render å¤±è´¥: {e}")
            
            # æ–¹æ³•2: ä½¿ç”¨Blenderå†…ç½®ä¿å­˜æ–¹æ³•
            try:
                print("ä½¿ç”¨Blenderå†…ç½®ä¿å­˜æ–¹æ³•...")
                
                width, height = image.size
                if width <= 0 or height <= 0:
                    print(f"æ— æ•ˆçš„å›¾åƒå°ºå¯¸: {width}x{height}")
                    return None
                
                # è·å–åƒç´ æ•°æ®
                if hasattr(image, 'pixels') and image.pixels is not None:
                    pixels = image.pixels[:]
                    if len(pixels) == 0:
                        print("åƒç´ æ•°æ®ä¸ºç©º")
                        return None
                    
                    print(f"åƒç´ æ•°æ®é•¿åº¦: {len(pixels)}")
                    
                    # åˆ›å»ºä¸´æ—¶å›¾åƒå¹¶ä¿å­˜
                    temp_image = bpy.data.images.new("temp_for_ai_save", width, height)
                    temp_image.pixels = pixels
                    temp_image.file_format = 'PNG'
                    temp_image.filepath_raw = temp_path
                    temp_image.save()
                    
                    # æ¸…ç†ä¸´æ—¶å›¾åƒ
                    bpy.data.images.remove(temp_image)
                    
                    if os.path.exists(temp_path):
                        size = os.path.getsize(temp_path)
                        print(f"âœ… Blenderå†…ç½®ä¿å­˜æˆåŠŸï¼Œæ–‡ä»¶å¤§å°: {size} bytes")
                        return temp_path
                    else:
                        print("Blenderå†…ç½®ä¿å­˜æœªåˆ›å»ºæ–‡ä»¶")
                
                else:
                    print("æ— æ³•è®¿é—®åƒç´ æ•°æ®")
                    
            except Exception as e:
                print(f"Blenderå†…ç½®ä¿å­˜å¤±è´¥: {e}")
            
            # æ–¹æ³•3: å¦‚æœå›¾åƒæ˜¯ä»æ–‡ä»¶åŠ è½½çš„ï¼Œå°è¯•ä½¿ç”¨åŸå§‹æ–‡ä»¶è·¯å¾„
            try:
                print("æ£€æŸ¥åŸå§‹æ–‡ä»¶è·¯å¾„...")
                if hasattr(image, 'filepath') and image.filepath:
                    source_path = bpy.path.abspath(image.filepath)
                    if os.path.exists(source_path):
                        import shutil
                        shutil.copy2(source_path, temp_path)
                        if os.path.exists(temp_path):
                            size = os.path.getsize(temp_path)
                            print(f"âœ… æ–‡ä»¶å¤åˆ¶æˆåŠŸï¼Œæ–‡ä»¶å¤§å°: {size} bytes")
                            return temp_path
                        else:
                            print("æ–‡ä»¶å¤åˆ¶æœªåˆ›å»ºç›®æ ‡æ–‡ä»¶")
                    else:
                        print(f"æºæ–‡ä»¶ä¸å­˜åœ¨: {source_path}")
                else:
                    print("å›¾åƒæ²¡æœ‰æœ‰æ•ˆçš„æ–‡ä»¶è·¯å¾„")
            except Exception as e:
                print(f"æ–‡ä»¶å¤åˆ¶æ–¹æ³•å¤±è´¥: {e}")
            
            print("âŒ æ‰€æœ‰ä¿å­˜æ–¹æ³•éƒ½å¤±è´¥äº†")
            return None
            
        except Exception as e:
            print(f"ä¿å­˜ä¸´æ—¶å›¾åƒå®Œå…¨å¤±è´¥: {e}")
            return None
    
    def build_image_generation_prompt(self, context, props):
        """Build comprehensive prompt for AI image generation with enhanced templates"""
        # 1. Get main prompt
        main_prompt = props.image_prompt.strip() if props.image_prompt.strip() else props.prompt.strip()
        if not main_prompt:
            main_prompt = "generate a high quality image"
        
        # 2. Apply prompt style templates
        enhanced_prompt = self.apply_prompt_template(main_prompt, props)
        
        # 3. Add lighting and camera details
        enhanced_prompt = self.add_technical_details(enhanced_prompt, props)
        
        # 4. Add scene context if enabled
        if props.include_scene_context:
            scene_info = self.get_scene_context(context)
            enhanced_prompt += f" | Scene context: {scene_info}"
        
        # 5. Add quality specifications
        quality_specs = {
            'LOW': "quick generation, basic quality",
            'MEDIUM': "balanced quality and detail, photorealistic",
            'HIGH': "high quality, ultra-detailed, professional photography, 8K resolution"
        }
        
        if props.quality in quality_specs:
            enhanced_prompt += f" | Quality: {quality_specs[props.quality]}"
        
        # 6. Add aspect ratio hint
        aspect_descriptions = {
            '1:1': "square composition",
            '2:3': "vertical portrait composition", 
            '3:2': "horizontal landscape composition",
            '3:4': "portrait orientation",
            '4:3': "landscape orientation",
            '4:5': "portrait format",
            '5:4': "landscape format",
            '9:16': "vertical mobile format",
            '16:9': "widescreen cinematic format",
            '21:9': "ultra-wide cinematic format"
        }
        
        if props.aspect_ratio in aspect_descriptions:
            enhanced_prompt += f" | Composition: {aspect_descriptions[props.aspect_ratio]}"
        
        return enhanced_prompt
    
    def apply_prompt_template(self, main_prompt, props):
        """Apply style-specific prompt templates"""
        if props.prompt_style == 'PHOTOREALISTIC':
            return f"A photorealistic scene of {main_prompt}, captured with professional camera equipment, emphasizing natural lighting and fine details"
        
        elif props.prompt_style == 'ARTISTIC':
            return f"A stylized artistic illustration of {main_prompt}, featuring creative interpretation and enhanced visual appeal"
        
        elif props.prompt_style == 'PRODUCT':
            return f"A high-resolution, studio-lit product photograph of {main_prompt}, with clean background and professional lighting setup to showcase key features"
        
        elif props.prompt_style == 'MINIMALIST':
            return f"A minimalist composition featuring {main_prompt}, with significant negative space, clean lines, and subtle lighting"
        
        elif props.prompt_style == 'COMIC':
            return f"A comic book style panel showing {main_prompt}, with bold lines, dynamic composition and vivid colors"
        
        else:  # CUSTOM
            return main_prompt
    
    def add_technical_details(self, prompt, props):
        """Add lighting and camera angle details to prompt"""
        technical_parts = [prompt]
        
        # Add lighting style
        if props.lighting_style != 'AUTO':
            lighting_descriptions = {
                'NATURAL': "natural sunlight, soft daylight illumination",
                'STUDIO': "professional studio lighting, three-point lighting setup",
                'CINEMATIC': "dramatic cinematic lighting with strong contrast",
                'GOLDEN_HOUR': "warm golden hour lighting, soft sunset glow",
                'BLUE_HOUR': "cool blue hour atmosphere, twilight ambiance",
                'LOW_KEY': "low key lighting, dramatic shadows and highlights",
                'HIGH_KEY': "high key lighting, bright and evenly illuminated"
            }
            
            if props.lighting_style in lighting_descriptions:
                technical_parts.append(f"Lighting: {lighting_descriptions[props.lighting_style]}")
        
        # Add camera angle
        if props.camera_angle != 'AUTO':
            angle_descriptions = {
                'EYE_LEVEL': "eye-level perspective, natural human viewpoint",
                'LOW_ANGLE': "low angle shot, looking up from below",
                'HIGH_ANGLE': "high angle shot, looking down from above", 
                'BIRDS_EYE': "bird's eye view, top-down aerial perspective",
                'WORMS_EYE': "worm's eye view, extreme low angle upward",
                'CLOSE_UP': "close-up shot, detailed macro perspective",
                'WIDE_SHOT': "wide shot, expansive environmental view"
            }
            
            if props.camera_angle in angle_descriptions:
                technical_parts.append(f"Camera: {angle_descriptions[props.camera_angle]}")
        
        return " | ".join(technical_parts)
    
    def process_gemini_analysis_response(self, response):
        """Process Gemini analysis response and extract rendering advice"""
        try:
            print("=== åˆ†æGeminiå“åº” ===")
            
            if 'candidates' in response and response['candidates']:
                candidate = response['candidates'][0]
                content = candidate.get('content', {})
                parts = content.get('parts', [])
                
                for part in parts:
                    if 'text' in part:
                        analysis_text = part['text']
                        print(f"âœ… è·å–åˆ°åˆ†ææ–‡æœ¬ï¼Œé•¿åº¦: {len(analysis_text)} å­—ç¬¦")
                        print(f"åˆ†æå†…å®¹å‰300å­—ç¬¦: {analysis_text[:300]}")
                        return analysis_text
                        
            print("âŒ å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ°æ–‡æœ¬å†…å®¹")
            return None
            
        except Exception as e:
            print(f"å¤„ç†åˆ†æå“åº”æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def save_analysis_result(self, context, analysis_text):
        """Save AI analysis result to file"""
        try:
            from .properties import get_nano_banana_output_dir
            import os
            from datetime import datetime
            
            output_dir = get_nano_banana_output_dir(context)
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)
            
            # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"AI_Analysis_{timestamp}.md"
            filepath = os.path.join(output_dir, filename)
            
            # æ ¼å¼åŒ–åˆ†æç»“æœ
            formatted_content = f"""# NanoBanana AI æ¸²æŸ“åˆ†ææŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## AI åˆ†æå’Œå»ºè®®

{analysis_text}

---
*ç”± Blender NanoBanana æ’ä»¶ç”Ÿæˆ*
"""
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(formatted_content)
            
            print(f"âœ… åˆ†æç»“æœå·²ä¿å­˜åˆ°: {filepath}")
            self.report({'INFO'}, f"åˆ†æç»“æœå·²ä¿å­˜: {filename}")
            
        except Exception as e:
            print(f"ä¿å­˜åˆ†æç»“æœå¤±è´¥: {e}")
            self.report({'WARNING'}, f"ä¿å­˜åˆ†æç»“æœå¤±è´¥: {e}")
    
    def save_generated_image(self, context, blender_image):
        """Save generated image to output directory with version control"""
        try:
            from .properties import get_nano_banana_output_dir
            import os
            from datetime import datetime
            
            output_dir = get_nano_banana_output_dir(context)
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)
            
            # åˆ›å»ºå¸¦ç‰ˆæœ¬æ§åˆ¶çš„æ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_filename = f"Generated_Image_{timestamp}"
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨åŒåæ–‡ä»¶ï¼Œæ·»åŠ ç‰ˆæœ¬åç¼€
            version = 1
            filename = f"{base_filename}.png"
            filepath = os.path.join(output_dir, filename)
            
            while os.path.exists(filepath):
                filename = f"{base_filename}.{version:03d}.png"
                filepath = os.path.join(output_dir, filename)
                version += 1
            
            # ä¿å­˜Blenderå›¾åƒåˆ°æ–‡ä»¶
            blender_image.save_render(filepath)
            
            print(f"âœ… ç”Ÿæˆçš„å›¾åƒå·²ä¿å­˜åˆ°: {filepath}")
            self.report({'INFO'}, f"ç”Ÿæˆå›¾åƒå·²ä¿å­˜: {filename}")
            
        except Exception as e:
            print(f"ä¿å­˜ç”Ÿæˆå›¾åƒå¤±è´¥: {e}")
            self.report({'WARNING'}, f"ä¿å­˜ç”Ÿæˆå›¾åƒå¤±è´¥: {e}")
    
    def save_debug_response(self, context, response_data):
        """Save API response for debugging"""
        try:
            from .properties import get_nano_banana_output_dir
            import json
            import os
            from datetime import datetime
            
            output_dir = get_nano_banana_output_dir(context)
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)
            
            # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"Debug_Response_{timestamp}.json"
            filepath = os.path.join(output_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(response_data, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… è°ƒè¯•å“åº”å·²ä¿å­˜åˆ°: {filepath}")
            self.report({'INFO'}, f"è°ƒè¯•å“åº”å·²ä¿å­˜: {filename}")
            
        except Exception as e:
            print(f"ä¿å­˜è°ƒè¯•å“åº”å¤±è´¥: {e}")
    
    def apply_ai_suggestions_and_render(self, context, analysis_text):
        """Apply AI suggestions to scene and create improved render"""
        try:
            print("=== åº”ç”¨AIå»ºè®®åˆ°åœºæ™¯ ===")
            scene = context.scene
            
            # ä¿å­˜åŸå§‹è®¾ç½®
            original_engine = scene.render.engine
            original_samples = getattr(scene.cycles, 'samples', 128) if hasattr(scene, 'cycles') else 128
            
            # 1. æ”¹è¿›ç…§æ˜è®¾ç½®
            self.improve_lighting_based_on_analysis(context, analysis_text)
            
            # 2. ä¼˜åŒ–æ¸²æŸ“è®¾ç½®
            self.optimize_render_settings(context, analysis_text)
            
            # 3. æ”¹è¿›æè´¨ï¼ˆå¦‚æœåˆ†æä¸­æåˆ°ï¼‰
            self.improve_materials_based_on_analysis(context, analysis_text)
            
            # 4. é‡æ–°æ¸²æŸ“åœºæ™¯
            print("é‡æ–°æ¸²æŸ“æ”¹è¿›çš„åœºæ™¯...")
            self.report({'INFO'}, "é‡æ–°æ¸²æŸ“æ”¹è¿›çš„åœºæ™¯...")
            
            # ä½¿ç”¨æ›´é«˜è´¨é‡çš„è®¾ç½®æ¸²æŸ“
            if scene.render.engine == 'BLENDER_EEVEE':
                # EEVEEä¼˜åŒ–è®¾ç½®
                eevee = scene.eevee
                eevee.use_ssr = True
                eevee.use_ssr_refraction = True  
                eevee.use_bloom = True
                eevee.bloom_intensity = 0.1
                
            elif scene.render.engine == 'CYCLES':
                # Cyclesä¼˜åŒ–è®¾ç½®
                scene.cycles.samples = 256
                scene.cycles.use_denoising = True
                
            # æ¸²æŸ“åˆ°ä¸´æ—¶æ–‡ä»¶
            import tempfile
            import os
            
            temp_dir = tempfile.gettempdir()
            improved_file = os.path.join(temp_dir, "nano_banana_improved_render.png")
            
            original_filepath = scene.render.filepath
            scene.render.filepath = improved_file
            
            # æ‰§è¡Œæ¸²æŸ“
            bpy.ops.render.render(write_still=True)
            
            # æ¢å¤åŸå§‹è®¾ç½®
            scene.render.filepath = original_filepath
            scene.render.engine = original_engine
            if hasattr(scene, 'cycles'):
                scene.cycles.samples = original_samples
            
            # æ£€æŸ¥æ–‡ä»¶å¹¶åŠ è½½
            if os.path.exists(improved_file):
                file_size = os.path.getsize(improved_file)
                print(f"æ”¹è¿›çš„æ¸²æŸ“æ–‡ä»¶åˆ›å»ºæˆåŠŸ: {file_size} bytes")
                
                # åŠ è½½æ”¹è¿›çš„å›¾åƒ
                improved_image = bpy.data.images.load(improved_file)
                improved_image.name = "NanoBanana_Improved_Render"
                
                # ä¿å­˜åˆ°è¾“å‡ºç›®å½•
                self.save_improved_render(context, improved_file)
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.unlink(improved_file)
                except:
                    pass
                    
                return improved_image
            else:
                print("æ”¹è¿›çš„æ¸²æŸ“æ–‡ä»¶æœªåˆ›å»º")
                self.report({'WARNING'}, "æ”¹è¿›çš„æ¸²æŸ“æ–‡ä»¶æœªåˆ›å»º")
                return None
                
        except Exception as e:
            print(f"åº”ç”¨AIå»ºè®®å¤±è´¥: {e}")
            self.report({'ERROR'}, f"åº”ç”¨AIå»ºè®®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def improve_lighting_based_on_analysis(self, context, analysis_text):
        """Improve lighting based on AI analysis"""
        try:
            scene = context.scene
            
            # æ£€æŸ¥æ˜¯å¦æåˆ°äº†ç…§æ˜æ”¹è¿›
            lighting_keywords = ['ç…§æ˜', 'å…‰æº', 'ä¸»å…‰æº', 'è¡¥å……å…‰', 'lighting', 'light']
            if any(keyword in analysis_text for keyword in lighting_keywords):
                print("æ ¹æ®AIå»ºè®®æ”¹è¿›ç…§æ˜...")
                
                # æ·»åŠ ä¸»å…‰æºï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                lights = [obj for obj in scene.objects if obj.type == 'LIGHT']
                if len(lights) < 2:
                    # æ·»åŠ ä¸»å…‰æº
                    bpy.ops.object.light_add(type='SUN', location=(5, 5, 10))
                    sun_light = context.active_object
                    sun_light.name = "AI_Main_Light"
                    sun_light.data.energy = 3.0
                    
                    # æ·»åŠ è¡¥å……å…‰
                    bpy.ops.object.light_add(type='AREA', location=(-3, 2, 5))
                    area_light = context.active_object
                    area_light.name = "AI_Fill_Light"
                    area_light.data.energy = 1.5
                    area_light.data.size = 2.0
                
                print("ç…§æ˜æ”¹è¿›å®Œæˆ")
                
        except Exception as e:
            print(f"ç…§æ˜æ”¹è¿›å¤±è´¥: {e}")
    
    def optimize_render_settings(self, context, analysis_text):
        """Optimize render settings based on AI analysis"""
        try:
            scene = context.scene
            
            # æ ¹æ®åˆ†æå»ºè®®ä¼˜åŒ–æ¸²æŸ“å¼•æ“
            if 'cycles' in analysis_text.lower() or 'å…‰çº¿è¿½è¸ª' in analysis_text:
                scene.render.engine = 'CYCLES'
                if hasattr(scene, 'cycles'):
                    scene.cycles.samples = 256
                    scene.cycles.use_denoising = True
                print("åˆ‡æ¢åˆ°Cyclesæ¸²æŸ“å¼•æ“")
            else:
                scene.render.engine = 'BLENDER_EEVEE'
                print("ä½¿ç”¨EEVEEæ¸²æŸ“å¼•æ“")
                
        except Exception as e:
            print(f"æ¸²æŸ“è®¾ç½®ä¼˜åŒ–å¤±è´¥: {e}")
    
    def improve_materials_based_on_analysis(self, context, analysis_text):
        """Improve materials based on AI analysis"""
        try:
            # æ£€æŸ¥æ˜¯å¦æåˆ°äº†æè´¨æ”¹è¿›
            material_keywords = ['æè´¨', 'çº¹ç†', 'material', 'texture', 'PBR']
            if any(keyword in analysis_text for keyword in material_keywords):
                print("æ ¹æ®AIå»ºè®®æ”¹è¿›æè´¨...")
                
                # ä¸ºåœºæ™¯ä¸­çš„ç½‘æ ¼å¯¹è±¡æ·»åŠ åŸºæœ¬çš„PBRæè´¨
                for obj in context.scene.objects:
                    if obj.type == 'MESH' and len(obj.material_slots) == 0:
                        # åˆ›å»ºæ–°æè´¨
                        mat = bpy.data.materials.new(name=f"AI_Enhanced_{obj.name}")
                        mat.use_nodes = True
                        
                        # è·å–æè´¨èŠ‚ç‚¹
                        nodes = mat.node_tree.nodes
                        bsdf = nodes.get("Principled BSDF")
                        
                        if bsdf:
                            # è®¾ç½®åŸºæœ¬çš„PBRå±æ€§
                            bsdf.inputs['Base Color'].default_value = (0.7, 0.7, 0.7, 1.0)
                            bsdf.inputs['Metallic'].default_value = 0.1
                            bsdf.inputs['Roughness'].default_value = 0.4
                            
                        # åˆ†é…æè´¨åˆ°å¯¹è±¡
                        obj.data.materials.append(mat)
                
                print("æè´¨æ”¹è¿›å®Œæˆ")
                
        except Exception as e:
            print(f"æè´¨æ”¹è¿›å¤±è´¥: {e}")
    
    def save_improved_render(self, context, temp_file_path):
        """Save improved render to output directory"""
        try:
            from .properties import get_nano_banana_output_dir
            import shutil
            from datetime import datetime
            
            output_dir = get_nano_banana_output_dir(context)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            final_filename = f"Improved_Render_{timestamp}.png"
            final_path = os.path.join(output_dir, final_filename)
            
            shutil.copy2(temp_file_path, final_path)
            print(f"æ”¹è¿›çš„æ¸²æŸ“å·²ä¿å­˜åˆ°: {final_path}")
            self.report({'INFO'}, f"æ”¹è¿›æ¸²æŸ“å·²ä¿å­˜: {final_filename}")
            
        except Exception as e:
            print(f"ä¿å­˜æ”¹è¿›æ¸²æŸ“å¤±è´¥: {e}")
    
    def process_gemini_image_response(self, response):
        """Process Gemini 2.5 Flash Image API response"""
        try:
            print("=== å¤„ç†Geminiå“åº” ===")
            
            if 'candidates' in response and response['candidates']:
                candidate = response['candidates'][0]
                content = candidate.get('content', {})
                parts = content.get('parts', [])
                
                print(f"æ‰¾åˆ° {len(parts)} ä¸ªparts")
                
                for i, part in enumerate(parts):
                    print(f"å¤„ç†Part {i}: {list(part.keys()) if isinstance(part, dict) else type(part)}")
                    
                    # æ£€æŸ¥inlineData (æ­£ç¡®çš„Geminiå­—æ®µå)
                    if 'inlineData' in part:
                        inline_data = part['inlineData']
                        print(f"å‘ç°inlineData: {list(inline_data.keys()) if isinstance(inline_data, dict) else type(inline_data)}")
                        
                        if isinstance(inline_data, dict) and 'data' in inline_data:
                            print("âœ… åœ¨inlineDataä¸­æ‰¾åˆ°å›¾åƒæ•°æ®")
                            try:
                                # è·å–base64æ•°æ®
                                base64_data = inline_data['data']
                                print(f"Base64æ•°æ®é•¿åº¦: {len(base64_data)} å­—ç¬¦")
                                
                                # è§£ç å›¾åƒæ•°æ®
                                image_bytes = base64.b64decode(base64_data)
                                print(f"âœ… æˆåŠŸè§£ç å›¾åƒæ•°æ®ï¼Œå¤§å°: {len(image_bytes)} bytes")
                                
                                # åˆ›å»ºBlenderå›¾åƒ
                                return self.create_blender_image_from_bytes(image_bytes)
                                
                            except Exception as e:
                                print(f"âŒ è§£ç inlineDataå¤±è´¥: {e}")
                                import traceback
                                traceback.print_exc()
                    
                    # å¤‡ç”¨æ–¹æ³•ï¼šæ£€æŸ¥textå“åº”
                    elif 'text' in part:
                        text_content = part['text']
                        print(f"æ”¶åˆ°æ–‡æœ¬å“åº”ï¼Œé•¿åº¦: {len(text_content)} å­—ç¬¦")
                        print(f"æ–‡æœ¬å†…å®¹: {text_content[:200]}...")
                        
                        # å¦‚æœæ–‡æœ¬æåˆ°äº†å›¾åƒä½†æ²¡æœ‰æ•°æ®ï¼Œå¯èƒ½æ˜¯APIé—®é¢˜
                        if any(keyword in text_content.lower() for keyword in ['image', 'generated', 'created']):
                            print("âš ï¸ æ–‡æœ¬å“åº”æåˆ°äº†å›¾åƒç”Ÿæˆï¼Œä½†æœªæ‰¾åˆ°å›¾åƒæ•°æ®")
                        
                        return text_content
                    
                    else:
                        print(f"æœªçŸ¥çš„partç±»å‹ï¼Œé”®: {list(part.keys()) if isinstance(part, dict) else 'Not a dict'}")
                        
            else:
                print("âŒ å“åº”ä¸­æ²¡æœ‰candidates")
                
        except Exception as e:
            print(f"âŒ å¤„ç†Geminiå“åº”æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
        
        print("âŒ æœªåœ¨å“åº”ä¸­æ‰¾åˆ°ä»»ä½•å›¾åƒæ•°æ®")
        return None
    
    def fallback_text_to_image(self, response, context):
        """Fallback method when no image is directly generated"""
        try:
            # ä»å“åº”ä¸­æå–æ–‡æœ¬æè¿°
            description = None
            if 'candidates' in response and response['candidates']:
                candidate = response['candidates'][0]
                content = candidate.get('content', {})
                parts = content.get('parts', [])
                
                for part in parts:
                    if 'text' in part:
                        description = part['text']
                        break
            
            if description:
                print(f"Using text description for image generation: {description}")
                # è¿™é‡Œå¯ä»¥å®ç°ä¸€ä¸ªæ–‡æœ¬åˆ°å›¾åƒçš„ç”Ÿæˆå™¨
                # ç›®å‰è¿”å›æè¿°æ–‡æœ¬ï¼Œç”¨æˆ·å¯ä»¥çœ‹åˆ°AIçš„å»ºè®®
                return f"AI Description: {description}"
            
        except Exception as e:
            print(f"Error in fallback text to image: {e}")
        
        return None
    
    def create_blender_image_from_bytes(self, image_bytes):
        """Create Blender image from bytes data"""
        try:
            import tempfile
            from datetime import datetime
            
            # åˆ›å»ºæ—¶é—´æˆ³
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # ç¡®å®šä¿å­˜è·¯å¾„
            if bpy.data.is_saved:
                # å¦‚æœæ–‡ä»¶å·²ä¿å­˜ï¼Œä¿å­˜åˆ°åŒä¸€ç›®å½•ä¸‹çš„NanoBananaæ–‡ä»¶å¤¹
                blend_dir = os.path.dirname(bpy.data.filepath)
                output_dir = os.path.join(blend_dir, "NanoBanana")
                os.makedirs(output_dir, exist_ok=True)
                permanent_path = os.path.join(output_dir, f"AI_Generated_{timestamp}.png")
            else:
                # å¦‚æœæ–‡ä»¶æœªä¿å­˜ï¼Œä¿å­˜åˆ°ä¸´æ—¶ç›®å½•
                output_dir = tempfile.gettempdir()
                permanent_path = os.path.join(output_dir, f"NanoBanana_AI_Generated_{timestamp}.png")
            
            # ä¿å­˜å›¾åƒæ•°æ®åˆ°æ°¸ä¹…æ–‡ä»¶
            with open(permanent_path, 'wb') as perm_file:
                perm_file.write(image_bytes)
            
            print(f"âœ… å›¾åƒå·²ä¿å­˜åˆ°: {permanent_path}")
            
            # åŠ è½½åˆ°Blender
            image_name = "NanoBanana_Render"
            if image_name in bpy.data.images:
                bpy.data.images.remove(bpy.data.images[image_name])
            
            image = bpy.data.images.load(permanent_path)
            image.name = image_name
            
            # ğŸ¯ è‡ªåŠ¨å¼¹å‡ºæ¸²æŸ“ç»“æœçª—å£ (åƒF12ä¸€æ ·)
            self.show_render_result(image)
            
            print(f"âœ… æˆåŠŸåˆ›å»ºBlenderå›¾åƒ: {image_name}")
            print(f"ğŸ“ å›¾åƒæ–‡ä»¶ä¿å­˜ä½ç½®: {permanent_path}")
            
            return image
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºBlenderå›¾åƒå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def show_render_result(self, image):
        """æ˜¾ç¤ºæ¸²æŸ“ç»“æœï¼Œæ¨¡æ‹ŸF12çš„æ•ˆæœ"""
        try:
            # æ–¹æ³•1: å°è¯•è°ƒç”¨æ¸²æŸ“ç»“æœæ˜¾ç¤º
            bpy.ops.render.view_show('INVOKE_DEFAULT')
            
            # æ–¹æ³•2: å¦‚æœæ²¡æœ‰æ¸²æŸ“ç»“æœçª—å£ï¼Œåˆ›å»ºæ–°çš„å›¾åƒæŸ¥çœ‹å™¨çª—å£
            # è·å–å½“å‰çª—å£
            current_window = bpy.context.window
            current_screen = current_window.screen
            
            # æŸ¥æ‰¾ç°æœ‰çš„å›¾åƒç¼–è¾‘å™¨
            image_editor_found = False
            for area in current_screen.areas:
                if area.type == 'IMAGE_EDITOR':
                    for space in area.spaces:
                        if space.type == 'IMAGE_EDITOR':
                            space.image = image
                            # ç¡®ä¿æ˜¾ç¤ºå›¾åƒ
                            area.tag_redraw()
                            image_editor_found = True
                            print("âœ… åœ¨ç°æœ‰å›¾åƒç¼–è¾‘å™¨ä¸­æ˜¾ç¤º")
                            break
                    break
            
            # å¦‚æœæ²¡æ‰¾åˆ°å›¾åƒç¼–è¾‘å™¨ï¼Œå°è¯•åœ¨æ–°çª—å£ä¸­æ˜¾ç¤º
            if not image_editor_found:
                try:
                    # åˆ›å»ºæ–°çš„å›¾åƒæŸ¥çœ‹å™¨çª—å£
                    bpy.ops.screen.userpref_show('INVOKE_DEFAULT')
                    print("âœ… å°è¯•åˆ›å»ºæ–°çª—å£æ˜¾ç¤ºå›¾åƒ")
                except:
                    pass
                    
            # æ–¹æ³•3: åœ¨æ¸²æŸ“å±æ€§ä¸­æ˜¾ç¤º
            for area in current_screen.areas:
                if area.type == 'PROPERTIES':
                    for space in area.spaces:
                        if space.type == 'PROPERTIES' and space.context == 'RENDER':
                            area.tag_redraw()
                            break
                    break
                    
            print("ğŸ–¼ï¸ æ¸²æŸ“ç»“æœå·²æ˜¾ç¤º")
            
        except Exception as e:
            print(f"âš ï¸ æ˜¾ç¤ºæ¸²æŸ“ç»“æœæ—¶å‡ºé”™: {e}")
            # å¤‡ç”¨æ–¹æ³•ï¼šè‡³å°‘ç¡®ä¿åœ¨å›¾åƒç¼–è¾‘å™¨ä¸­å¯è§
            try:
                for area in bpy.context.screen.areas:
                    if area.type == 'IMAGE_EDITOR':
                        for space in area.spaces:
                            if space.type == 'IMAGE_EDITOR':
                                space.image = image
                                area.tag_redraw()
                                break
                        break
            except:
                pass
    
    def get_scene_context(self, context):
        """Extract context from current scene"""
        scene = context.scene
        
        # Count objects by type
        mesh_count = len([obj for obj in scene.objects if obj.type == 'MESH'])
        light_count = len([obj for obj in scene.objects if obj.type == 'LIGHT'])
        camera_count = len([obj for obj in scene.objects if obj.type == 'CAMERA'])
        
        context_info = f"Scene with {mesh_count} meshes, {light_count} lights, {camera_count} cameras"
        
        # Add lighting info if available
        if scene.world and scene.world.use_nodes:
            context_info += ", world lighting enabled"
        
        return context_info
    
    def process_gemini_response(self, response):
        """Process Gemini API response"""
        # This is a simplified implementation
        # Gemini typically returns text, so this would need integration
        # with an image generation service
        try:
            if 'candidates' in response and response['candidates']:
                content = response['candidates'][0].get('content', {})
                parts = content.get('parts', [])
                if parts and 'text' in parts[0]:
                    # For now, create a simple text display
                    # In a real implementation, you'd need image generation
                    text_result = parts[0]['text']
                    print(f"Gemini response: {text_result}")
                    return text_result
        except Exception as e:
            print(f"Error processing response: {e}")
        
        return None
    
    def display_result(self, context, result):
        """Display the generated result"""
        if isinstance(result, bpy.types.Image):
            print(f"Displaying generated image: {result.name}")
            # Display image in Image Editor
            self.show_image_in_editor(context, result)
            
            # Also save to file
            self.save_result_image(result)
            
            # Force UI update
            for area in context.screen.areas:
                area.tag_redraw()
            
            print(f"AI Render completed! Image: {result.name} is now available in Image Editor")
        elif isinstance(result, str):
            # Handle text response (AI description)
            print(f"AI Response: {result}")
            # Could show this in a popup dialog
            self.show_text_result(context, result)
        else:
            # Fallback for other types
            print(f"AI Render Result: {result}")
    
    def show_text_result(self, context, text):
        """Show text result in a popup dialog"""
        def draw(self, context):
            layout = self.layout
            # Split long text into lines
            lines = text.split('\n')
            for line in lines:
                if len(line) > 60:
                    # Split long lines
                    words = line.split(' ')
                    current_line = ""
                    for word in words:
                        if len(current_line + word) < 60:
                            current_line += word + " "
                        else:
                            if current_line:
                                layout.label(text=current_line.strip())
                            current_line = word + " "
                    if current_line:
                        layout.label(text=current_line.strip())
                else:
                    layout.label(text=line)
        
        bpy.context.window_manager.popup_menu(draw, title="AI Rendering Result", icon='INFO')
    
    def show_image_in_editor(self, context, image):
        """Show the generated image in Blender's Image Editor and popup"""
        try:
            # Find or create an Image Editor area
            image_editor_area = None
            
            # First, try to find an existing Image Editor
            for area in context.screen.areas:
                if area.type == 'IMAGE_EDITOR':
                    image_editor_area = area
                    break
            
            # If no Image Editor found, try to convert one
            if not image_editor_area:
                for area in context.screen.areas:
                    if area.type in ['TEXT_EDITOR', 'CONSOLE', 'INFO']:
                        # Temporarily change area type
                        area.type = 'IMAGE_EDITOR'
                        image_editor_area = area
                        break
            
            # Set the image in the Image Editor
            if image_editor_area:
                for space in image_editor_area.spaces:
                    if space.type == 'IMAGE_EDITOR':
                        space.image = image
                        break
                        
            # Also set as render result for easy access
            if 'Render Result' in bpy.data.images:
                render_result = bpy.data.images['Render Result']
                # Copy the AI generated image to render result
                self.copy_image_to_render_result(image, render_result)
            
            # Show popup with image preview
            self.show_image_popup(context, image)
            
        except Exception as e:
            print(f"Error displaying image: {e}")
    
    def show_image_popup(self, context, image):
        """Show a large, centered popup with the generated image"""
        def draw_popup(self, context):
            layout = self.layout
            layout.scale_y = 1.2
            
            # Image dimensions
            img_width, img_height = image.size
            
            # Calculate display size (max 800x600, maintaining aspect ratio)
            max_width = 800
            max_height = 600
            
            if img_width > max_width or img_height > max_height:
                # Scale down while maintaining aspect ratio
                scale_w = max_width / img_width
                scale_h = max_height / img_height
                scale = min(scale_w, scale_h)
                display_width = int(img_width * scale)
                display_height = int(img_height * scale)
            else:
                display_width = img_width
                display_height = img_height
            
            # Title
            row = layout.row()
            row.alignment = 'CENTER'
            row.label(text="ğŸ¨ AIç”Ÿæˆç»“æœ", icon='IMAGE_DATA')
            
            layout.separator()
            
            # Image info
            info_row = layout.row()
            info_row.alignment = 'CENTER'
            info_row.label(text=f"å›¾ç‰‡å°ºå¯¸: {img_width} x {img_height} åƒç´ ")
            
            layout.separator()
            
            # Image display - use template_preview for better display
            col = layout.column(align=True)
            col.scale_x = max(1.0, display_width / 200)  # Scale UI element
            col.scale_y = max(1.0, display_height / 200)
            
            # Preview the image
            col.template_preview(image, show_buttons=False)
            
            layout.separator()
            
            # Action buttons
            button_row = layout.row(align=True)
            button_row.alignment = 'CENTER'
            
            # Save button
            save_op = button_row.operator("nano_banana.save_image", text="ğŸ’¾ ä¿å­˜å›¾ç‰‡", icon='FILE_IMAGE')
            save_op.image_name = image.name
            
            # View in Image Editor button
            view_op = button_row.operator("nano_banana.view_in_editor", text="ğŸ‘ï¸ åœ¨å›¾åƒç¼–è¾‘å™¨ä¸­æŸ¥çœ‹", icon='IMAGE_COL')
            view_op.image_name = image.name
        
        # Calculate popup size based on image
        popup_width = min(850, max(400, image.size[0] + 100))
        
        bpy.context.window_manager.popup_menu(
            draw_popup, 
            title="NanoBanana AIæ¸²æŸ“å®Œæˆ", 
            icon='RENDER_RESULT',
            width=popup_width
        )
    
    def copy_image_to_render_result(self, source_image, target_image):
        """Copy AI generated image to render result slot"""
        try:
            # This is a simplified approach
            # In practice, you might want to properly handle image buffers
            source_image.update()
            target_image.scale(source_image.size[0], source_image.size[1])
            
        except Exception as e:
            print(f"Error copying to render result: {e}")
    
    def save_input_image(self, image):
        """Save the input viewport image for debugging purposes"""
        try:
            import time
            
            print("å¼€å§‹ä¿å­˜è¾“å…¥è§†å£å›¾åƒ...")
            
            # ä½¿ç”¨æ–°çš„NanoBananaè¾“å‡ºç›®å½•
            output_dir = get_nano_banana_output_dir()
            print(f"ä½¿ç”¨NanoBananaè¾“å‡ºç›®å½•: {output_dir}")
            
            # ç”Ÿæˆæ—¶é—´æˆ³æ–‡ä»¶å
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"nano_banana_INPUT_{timestamp}.png"
            filepath = os.path.join(output_dir, filename)
            
            print(f"è¾“å…¥å›¾åƒä¿å­˜è·¯å¾„: {filepath}")
            
            # ä¿å­˜å›¾åƒ
            # ç¡®ä¿å›¾åƒæ•°æ®æ˜¯æœ€æ–°çš„
            image.update()
            
            # è®¾ç½®æ–‡ä»¶æ ¼å¼
            scene = bpy.context.scene
            original_format = scene.render.image_settings.file_format
            scene.render.image_settings.file_format = 'PNG'
            
            try:
                # ä¿å­˜å›¾åƒ
                image.save_render(filepath)
                print(f"è¾“å…¥è§†å£å›¾åƒå·²ä¿å­˜åˆ°: {filepath}")
                
                # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if os.path.exists(filepath):
                    file_size = os.path.getsize(filepath)
                    print(f"è¾“å…¥å›¾åƒæ–‡ä»¶ä¿å­˜æˆåŠŸï¼Œå¤§å°: {file_size} å­—èŠ‚")
                else:
                    print("è­¦å‘Šï¼šè¾“å…¥å›¾åƒæ–‡ä»¶ä¿å­˜å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨")
                    
            finally:
                # æ¢å¤åŸå§‹æ ¼å¼
                scene.render.image_settings.file_format = original_format
                
        except Exception as e:
            print(f"ä¿å­˜è¾“å…¥å›¾åƒæ—¶å‡ºé”™: {e}")

    def save_result_image(self, image):
        """Save the generated image to file"""
        try:
            import time
            
            print("å¼€å§‹ä¿å­˜AIæ¸²æŸ“ç»“æœ...")
            
            # ä½¿ç”¨æ–°çš„NanoBananaè¾“å‡ºç›®å½•
            output_dir = get_nano_banana_output_dir()
            print(f"ä½¿ç”¨NanoBananaè¾“å‡ºç›®å½•: {output_dir}")
            
            # ç”Ÿæˆæ—¶é—´æˆ³æ–‡ä»¶å
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"nano_banana_RESULT_{timestamp}.png"
            filepath = os.path.join(output_dir, filename)
            
            print(f"AIç»“æœä¿å­˜è·¯å¾„: {filepath}")
            
            # ä¿å­˜å›¾åƒ
            image.update()
            
            # è®¾ç½®æ–‡ä»¶æ ¼å¼
            scene = bpy.context.scene
            original_format = scene.render.image_settings.file_format
            scene.render.image_settings.file_format = 'PNG'
            
            try:
                # ä¿å­˜å›¾åƒ
                image.save_render(filepath)
                print(f"AIæ¸²æŸ“ç»“æœå·²ä¿å­˜åˆ°: {filepath}")
                
                # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if os.path.exists(filepath):
                    file_size = os.path.getsize(filepath)
                    print(f"AIç»“æœæ–‡ä»¶ä¿å­˜æˆåŠŸï¼Œå¤§å°: {file_size} å­—èŠ‚")
                    return filepath
                else:
                    print("è­¦å‘Šï¼šAIç»“æœæ–‡ä»¶ä¿å­˜å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨")
                    return None
                    
            finally:
                # æ¢å¤åŸå§‹æ ¼å¼
                scene.render.image_settings.file_format = original_format
                
        except Exception as e:
            print(f"ä¿å­˜AIç»“æœæ—¶å‡ºé”™: {e}")
            return None
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"nano_banana_render_{timestamp}.png"
            filepath = os.path.join(output_dir, filename)
            
            print(f"ä¿å­˜è·¯å¾„: {filepath}")
            
            # ä¿å­˜å›¾åƒ
            # ç¡®ä¿å›¾åƒæ•°æ®æ˜¯æœ€æ–°çš„
            image.update()
            
            # è®¾ç½®æ–‡ä»¶æ ¼å¼
            scene = bpy.context.scene
            original_format = scene.render.image_settings.file_format
            scene.render.image_settings.file_format = 'PNG'
            
            try:
                # ä¿å­˜å›¾åƒ
                image.save_render(filepath)
                print(f"AIæ¸²æŸ“å›¾åƒå·²ä¿å­˜åˆ°: {filepath}")
                
                # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if os.path.exists(filepath):
                    file_size = os.path.getsize(filepath)
                    print(f"æ–‡ä»¶ä¿å­˜æˆåŠŸï¼Œå¤§å°: {file_size} å­—èŠ‚")
                else:
                    print("è­¦å‘Šï¼šæ–‡ä»¶ä¿å­˜å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨")
                    
            finally:
                # æ¢å¤åŸå§‹æ ¼å¼
                scene.render.image_settings.file_format = original_format
            
            return filepath
            
        except Exception as e:
            print(f"ä¿å­˜å›¾åƒæ—¶å‡ºé”™: {e}")
            return None

class NANOBANANA_OT_render_animation(Operator):
    """Render animation sequence using Gemini AI"""
    bl_idname = "nano_banana.render_animation"
    bl_label = "Render Animation"
    bl_description = "Generate AI render sequence for animation"
    
    def execute(self, context):
        self.report({'INFO'}, "Animation rendering not yet implemented")
        return {'FINISHED'}


class NANOBANANA_OT_save_image(bpy.types.Operator):
    """Save the generated image to file"""
    bl_idname = "nano_banana.save_image"
    bl_label = "Save Image"
    bl_options = {'REGISTER'}
    
    image_name: bpy.props.StringProperty(name="Image Name")
    
    def execute(self, context):
        if self.image_name and self.image_name in bpy.data.images:
            image = bpy.data.images[self.image_name]
            
            # Use the save method from main operator
            main_op = NANOBANANA_OT_render_with_ai()
            main_op.save_result_image(image)
            
            self.report({'INFO'}, f"å›¾ç‰‡å·²ä¿å­˜: {self.image_name}")
        else:
            self.report({'ERROR'}, "å›¾ç‰‡ä¸å­˜åœ¨")
        
        return {'FINISHED'}


class NANOBANANA_OT_view_in_editor(bpy.types.Operator):
    """View image in Image Editor"""
    bl_idname = "nano_banana.view_in_editor"
    bl_label = "View in Image Editor"
    bl_options = {'REGISTER'}
    
    image_name: bpy.props.StringProperty(name="Image Name")
    
    def execute(self, context):
        if self.image_name and self.image_name in bpy.data.images:
            image = bpy.data.images[self.image_name]
            
            # Find or create an Image Editor area
            for area in context.screen.areas:
                if area.type == 'IMAGE_EDITOR':
                    for space in area.spaces:
                        if space.type == 'IMAGE_EDITOR':
                            space.image = image
                            area.tag_redraw()
                            break
                    break
            else:
                # No Image Editor found, try to create one
                for area in context.screen.areas:
                    if area.type in ['TEXT_EDITOR', 'CONSOLE', 'INFO']:
                        area.type = 'IMAGE_EDITOR'
                        for space in area.spaces:
                            if space.type == 'IMAGE_EDITOR':
                                space.image = image
                                area.tag_redraw()
                                break
                        break
            
            self.report({'INFO'}, f"åœ¨å›¾åƒç¼–è¾‘å™¨ä¸­æ˜¾ç¤º: {self.image_name}")
        else:
            self.report({'ERROR'}, "å›¾ç‰‡ä¸å­˜åœ¨")
        
        return {'FINISHED'}


# Export all operator classes
__all__ = [
    'NANOBANANA_OT_api_key_dialog',
    'NANOBANANA_OT_setup_api',
    'NANOBANANA_OT_capture_viewport',
    'NANOBANANA_OT_render_viewport',
    'NANOBANANA_OT_render_animation',
    'NANOBANANA_OT_save_image',
    'NANOBANANA_OT_view_in_editor',
]